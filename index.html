--- 
layout: default 
--- 
<nav>
  <div class="nav-container">
    <div class="nav-name"></div>
    <div class="nav-links">
      <a href="#about">About</a>
      <a href="#papers">Papers</a>
      <a href="#teaching">Teaching</a>
      <a href="#awards">Awards</a>
    </div>
  </div>
</nav>
<div class="container">
  <header class="header" id="about">
    <div class="profile-container float-left">
      <img src="/assets/gustaf.jpg" alt="Gustaf Ahdritz" class="profile-image">
      <div class="name-email">
        <h1>Gustaf Ahdritz</h1>
        <address class="address">
           <div><span class="addri"></span></div>
           <span class="addrj"></span>
           <div><span class="addrk"></span></div>
        </address>
      </div>
    </div>
    <div class="bio-container">
      <div class="bio">
        <p>I'm a third-year PhD student in Computer Science at Harvard University. I'm a member of the <a href="https://mlfoundations.org">Machine Learning Foundations Group</a> and am advised by <a href="https://boazbarak.org">Boaz&nbsp;Barak</a> and <a href="http://www.jfrankle.com">Jonathan&nbsp;Frankle</a>. I'm supported by a fellowship from Harvard's <a href="https://www.harvard.edu/kempner-institute/">Kempner Institute</a>. </p>
        <br>
        <p>I'm broadly interested in empirical investigations of the properties of realistic deep neural networks. At the moment, I'm thinking about uncertainty in large language models.</p>
        <br>
        <p>In the summer of 2024, I interned at Apple, where I worked with Parikshit Gopalan, Udi Wieder, Moises Goldszmidt, and Anatoly Adamov (et al.). I graduated from Columbia with a B.A. in Computer Science &amp; History (2020) and an M.S. in Computer Science (2021). There, I worked with <a href="https://aqlab.io">Mohammed AlQuraishi</a> on the applied task of protein structure prediction and led the development of <a href="https://www.github.com/aqlaboratory/openfold">OpenFold</a>.</p>
      </div>
      <div class="links">
        <a href="/assets/cv.pdf" class="paper-link">CV</a>
        <a href="https://github.com/gahdritz" class="paper-link">GitHub</a>
        <a href="https://scholar.google.com/citations?user=oCO_ClkAAAAJ&hl=en&oi=ao" class="paper-link">Google Scholar</a>
        <a href="https://twitter.com/gahdritz" class="paper-link">Twitter</a>
      </div>
    </div>
  </header>
  <section class="section" id="papers">
    <h2>Papers</h2>
    <h3>Preprints</h3>
    <div class="paper-cards">
      <div class="paper-card">
        <div class="paper-card-image">
          <img src="/assets/papers/rtic.jpg" alt="Real-Time Interactive Conversations">
        </div>
        <div class="badges">
          <div class="badge badge-preprint">Preprint</div>
        </div>
        <div class="paper-title">Modeling Real-Time Interactive Conversations as Timed Diarized Transcripts</div>
        <div class="authors">*Garrett Tanzer, *<strong>Gustaf Ahdritz</strong>, Luke Melas-Kyriazi </div>
        <div class="venue">2024</div>
        <div class="tldr">Carefully sampling from language models trained directly on timed, diarized transcripts (e.g. instant messenger logs) permits true real-time interactivity.</div>
        <div class="paper-links">
          <a href="https://arxiv.org/abs/2405.13203" class="paper-link">Paper</a>
          <a href="https://github.com/gahdritz/rtic" class="paper-link">Code</a>
          <a href="https://x.com/gahdritz/status/1797734092806717719" class="paper-link">Tweetorial</a>
          <a href="/bibtex/rtic.bib" class="paper-link">BibTex</a>
        </div>
      </div>
    </div>
    <h3>Conference Papers</h3>
    <div class="paper-cards">
     <div class="paper-card">
        <div class="paper-card-image">
          <img src="/assets/papers/provable_decomp.jpg" alt="Higher-Order Calibration">
        </div>
        <div class="badges">
          <div class="badge badge-conference">ICLR</div>
          <div class="badge badge-award">Spotlight</div>
        </div>
        <div class="paper-title">Provable Uncertainty Decomposition via Higher-Order Calibration</div>
        <div class="authors">
          <strong>Gustaf Ahdritz</strong>, Aravind Gollakota, Parikshit Gopalan, Charlotte Peale, Udi Wieder (Î±)
        </div>
        <div class="venue">2024</div>
        <div class="tldr">We define higher-order calibration, which turns out to be the necessary and sufficient condition for accurate uncertainty decomposition.</div>
        <div class="paper-links">
          <a href="https://openreview.net/forum?id=TId1SHe8JG" class="paper-link">Paper</a>
          <a href="/bibtex/hoc.bib" class="paper-link">BibTeX</a>
          <a href="https://x.com/gahdritz/status/1876346358535421954" class="paper-link">Tweetorial</a>
        </div>
      </div>

      <div class="paper-card">
        <div class="paper-card-image">
          <img src="/assets/papers/distinguishing.jpg" alt="Distinguishing Knowable from Unknowable">
        </div>
        <div class="badges">
          <div class="badge badge-conference">ICML</div>
        </div>
        <div class="paper-title">Distinguishing the Knowable from the Unknowable with Language Models</div>
        <div class="authors">*<strong>Gustaf Ahdritz</strong>, *Tian Qin, Nikhil Vyas, Boaz Barak, Benjamin L. Edelman </div>
        <div class="venue">2024</div>
        <div class="tldr">Linear probes of language model activations can predict when the predictive entropy of much larger and more knowledgeable models is close to zero, and they even work out-of-distribution!</div>
        <div class="paper-links">
          <a href="https://icml.cc/virtual/2024/poster/32819" class="paper-link">Paper</a>
          <a href="https://github.com/gahdritz/llm_uncertainty" class="paper-link">Code</a>
          <a href="https://x.com/gahdritz/status/1780618634832036174" class="paper-link">Tweetorial</a>
          <a href="/bibtex/distinguishing.bib" class="paper-link">BibTex</a>
        </div>
      </div>
      <div class="paper-card">
        <div class="paper-card-image">
          <img src="/assets/papers/openproteinset.jpg" alt="OpenProteinSet">
        </div>
        <div class="badges">
          <div class="badge badge-conference">NeurIPS</div>
        </div>
        <div class="paper-title">OpenProteinSet: Training data for structural biology at scale</div>
        <div class="authors">
          <strong>Gustaf Ahdritz</strong>, Nazim Bouatta, Sachin Kadyan, Lukas Jarosch, Daniel Berenberg, Ian Fisk, et al.
        </div>
        <div class="venue">2023</div>
        <div class="tldr">We present the largest open repository of precomputed multiple sequence alignments (MSAs) of proteins, representing millions of compute hours.</div>
        <div class="paper-links">
          <a href="https://neurips.cc/virtual/2023/poster/73507" class="paper-link">Paper</a>
          <a href="https://registry.opendata.aws/openfold/" class="paper-link">Data</a>
          <a href="/bibtex/openproteinset.bib" class="paper-link">BibTeX</a>
        </div>
      </div>
      <div class="paper-card">
        <div class="paper-card-image">
          <img src="/assets/papers/soft_prompts.jpg" alt="Soft Prompting">
        </div>
        <div class="badges">
          <div class="badge badge-conference">ICML Workshop</div>
        </div>
        <div class="paper-title">Soft prompting might be a bug, not a feature</div>
        <div class="authors">*Luke Bailey, *<strong>Gustaf Ahdritz</strong>, *Anat Kleiman, Siddharth Swaroop, Finale Doshi-Velez, Weiwei Pan </div>
        <div class="venue">2023</div>
        <div class="tldr">Contrary to prior speculation, we find that soft prompts (created with "prompt-" or "prefix-tuning") differ from natural token embeddings in key ways, complicating attempts to decode them back into natural language.</div>
        <div class="paper-links">
          <a href="https://openreview.net/forum?id=MHWDdMEJ5s" class="paper-link">Paper</a>
          <a href="/bibtex/soft_prompts.bib" class="paper-link">BibTeX</a>
        </div>
      </div>
    </div>
    <h3>Journal papers</h3>
    <div class="paper-cards">
      <div class="paper-card">
        <div class="paper-card-image">
          <img src="/assets/papers/openfold.jpg" alt="OpenFold">
        </div>
        <div class="badges">
          <div class="badge badge-journal">Nature Methods</div>
        </div>
        <div class="paper-title">OpenFold: Retraining AlphaFold2 yields new insights into its learning mechanisms and capacity for generalization</div>
        <div class="authors">*<strong>Gustaf Ahdritz</strong>, *Nazim Bouatta, Christina Floristean, Sachin Kadyan, Qinghui Xia, William Gerecke, et al. </div>
        <div class="venue">2024</div>
        <div class="tldr">We created the first trainable, open-source reproduction of AlphaFold2 and used it to study how the model learns to fold.</div>
        <div class="paper-links">
          <a href="https://www.nature.com/articles/s41592-024-02272-z" class="paper-link">Paper</a>
          <a href="https://www.github.com/aqlaboratory/openfold" class="paper-link">Code</a>
          <a href="https://www.youtube.com/watch?v=W92xVnUMkU0" class="paper-link">Talk</a>
          <a href="/bibtex/openfold.bib" class="paper-link">BibTex</a>
        </div>
      </div>
      <div class="paper-card">
        <div class="paper-card-image">
          <img src="/assets/papers/rgn2.jpg" alt="Single-sequence protein structure prediction">
        </div>
        <div class="badges">
          <div class="badge badge-journal">Nature Biotechnology</div>
        </div>
        <div class="paper-title">Single-sequence protein structure prediction using a language model and deep learning</div>
        <div class="authors">*Ratul Chowdhury, *Nazim Bouatta, *Surojit Biswas, *Christina Floristean, Anant Kharkar, <strong>Gustaf Ahdritz</strong>, et al. </div>
        <div class="venue">2022</div>
        <div class="tldr">We present RGN2, an end-to-end "single-sequence" protein structure prediction model that relies on a small protein language model rather than multiple sequence alignments.</div>
        <div class="paper-links">
          <a href="https://www.nature.com/articles/s41587-022-01432-w" class="paper-link">Paper</a>
          <a href="https://www.github.com/aqlaboratory/rgn2" class="paper-link">Code</a>
          <a href="/bibtex/rgn2.bib" class="paper-link">BibTeX</a>
        </div>
      </div>
    </div>
  </section>
  <section class="section" id="teaching">
    <h2>Teaching</h2>
    <p>I've served as a teaching fellow/assistant for the following courses at Harvard and Columbia:</p>
    <ul class="teaching-list">
      <li>
        <em>Spring 2023</em>: Foundations of Deep Learning (Harvard COMPSCI 229br) with Boaz Barak
      </li>
      <li>
        <em>Spring 2019 - Spring 2021</em>: Advanced Programming (Columbia COMS 3157) with Jae Woo Lee
      </li>
    </ul>
  </section>
  <section class="section" id="awards">
    <h2>Awards & Fellowships</h2>
    <ul class="awards-list">
      <li>
        <em>2023 - 2028</em>: <a href="https://www.harvard.edu/kempner-institute/2023/05/31/kempner-institute-announces-recipients-of-inaugural-graduate-student-fellowships/">Kempner Institute Graduate Fellowship</a> (Kempner Institute, Harvard)
      </li>
      <li>
        <em>2022 - 2028</em>: <a href="https://ashfordfellows.fas.harvard.edu/about">Ashford Fellowship</a> (Harvard)
      </li>
      <li>
        <em>2020</em>: Andrew P. Kosoresow Memorial Award for Excellence in Teaching and Service (Columbia SEAS)
      </li>
      <li>
        <em>2019</em>: Dean Hawkes Memorial Prize (Columbia College)
      </li>
    </ul>
  </section>
</div>
<footer class="footer">
  <p>Last updated: March 2025</p>
</footer>
